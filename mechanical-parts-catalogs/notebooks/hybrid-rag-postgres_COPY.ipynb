{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1f7051",
   "metadata": {},
   "source": [
    "## PoC for advanced RAG with PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d3724",
   "metadata": {},
   "source": [
    "___\n",
    "### Activate python virtual env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770bd314",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%source ~/path-to-your-project/llamaindex-venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fae8ca",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___\n",
    "## Setup Postgres and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f6725",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd964979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import subprocess\n",
    "\n",
    "def run_sudo(cmd, sudo_password, check=True):\n",
    "    \"\"\"Run a command with sudo -S, providing password via stdin.\"\"\"\n",
    "    return subprocess.run(\n",
    "        [\"sudo\", \"-S\"] + cmd,\n",
    "        input=(sudo_password + \"\\n\"),\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=check,\n",
    "        cwd=\"/tmp\",\n",
    "    )\n",
    "\n",
    "# --- passwords ---\n",
    "sudo_password = getpass.getpass(\"Provide sudo password: \")\n",
    "postgres_pw = getpass.getpass(\"Provide PostgreSQL password for user 'postgres': \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8789c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- system packages ---\n",
    "run_sudo([\"apt\", \"update\"], sudo_password)\n",
    "run_sudo([\"apt\", \"install\", \"-y\", \"postgresql-common\"], sudo_password)\n",
    "print(\"✅ system packages\")\n",
    "\n",
    "# Add PostgreSQL APT repo helper (from postgresql-common)\n",
    "run_sudo([\"/usr/share/postgresql-common/pgdg/apt.postgresql.org.sh\"], sudo_password)\n",
    "print(\"✅ PostgreSQL APT repo helper\")\n",
    "\n",
    "# Install PostgreSQL + pgvector\n",
    "command = \"sudo -S apt install postgresql-15-pgvector\"\n",
    "os.system(f'echo \"{sudo_password}\" | {command}')\n",
    "# run_sudo([\"apt\", \"install\", \"-y\", \"postgresql\", \"postgresql-15-pgvector\"], sudo_password)\n",
    "print(\"✅ Install PostgreSQL + pgvector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd560c",
   "metadata": {},
   "source": [
    "## Start and enable PostgreSQL service:\n",
    "Ensures the DB server is running and starts automatically on reboot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc34c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ service is running\n",
      "ALTER ROLE\n",
      "✅ set postgres user password\n"
     ]
    }
   ],
   "source": [
    "# Ensure service is running\n",
    "run_sudo([\"systemctl\", \"enable\", \"--now\", \"postgresql\"], sudo_password)\n",
    "print(\"✅ service is running\")\n",
    "\n",
    "# --- set postgres user password ---\n",
    "sql_set_pw = f\"ALTER USER postgres WITH PASSWORD '{postgres_pw}';\"\n",
    "res = subprocess.run(\n",
    "    [\"sudo\", \"-S\", \"-u\", \"postgres\", \"psql\", \"-c\", sql_set_pw],\n",
    "    input=(sudo_password + \"\\n\"),\n",
    "    text=True,\n",
    "    check=True,\n",
    "    cwd=\"/tmp\",\n",
    ")\n",
    "# print(\"Return code:\", res.returncode)\n",
    "# print(\"STDOUT:\\n\", res.stdout)\n",
    "# print(\"STDERR:\\n\", res.stderr)\n",
    "print(\"✅ set postgres user password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c4a5b",
   "metadata": {},
   "source": [
    "## Create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f34858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO\n",
      "✅ create database\n"
     ]
    }
   ],
   "source": [
    "# --- create database (idempotent) ---\n",
    "sql_create_db = \"CREATE DATABASE vector_db;\"\n",
    "# If DB exists, CREATE DATABASE fails; so check first with psql:\n",
    "sql_create_db_safe = \"\"\"\n",
    "DO $$\n",
    "BEGIN\n",
    "   IF NOT EXISTS (SELECT FROM pg_database WHERE datname = 'vector_db') THEN\n",
    "      CREATE DATABASE vector_db;\n",
    "   END IF;\n",
    "END $$;\n",
    "\"\"\"\n",
    "subprocess.run(\n",
    "    [\"sudo\", \"-S\", \"-u\", \"postgres\", \"psql\", \"-c\", sql_create_db_safe],\n",
    "    input=(sudo_password + \"\\n\"),\n",
    "    text=True,\n",
    "    check=True,\n",
    "    cwd=\"/tmp\",\n",
    ")\n",
    "print(\"✅ create database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca360177",
   "metadata": {},
   "source": [
    "### Connect to vector_db and enable pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgvector extension: ('vector', '0.8.2')\n",
      "✅ PostgreSQL + pgvector ready. DB: vector_db, user: postgres\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# --- connect with psycopg2 to the new DB and enable pgvector extension ---\n",
    "connection_string=f\"postgresql://postgres:{postgres_pw}@localhost:5432\"\n",
    "\n",
    "db_name = \"vector_db\"\n",
    "conn = psycopg2.connect(\n",
    "    dbname=db_name,\n",
    "    user=\"postgres\",\n",
    "    password=postgres_pw,\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    # c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    # c.execute(f\"CREATE DATABASE {db_name}\")\n",
    "    c.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    c.execute(\"SELECT extname, extversion FROM pg_extension WHERE extname='vector';\")\n",
    "    print(\"pgvector extension:\", c.fetchone())\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ PostgreSQL + pgvector ready. DB: vector_db, user: postgres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1152113",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79290c04",
   "metadata": {},
   "source": [
    "# RAG pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c1809",
   "metadata": {},
   "source": [
    "### Load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313141ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "if \"LLAMA_CLOUD_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass(\"Enter your Llama Cloud API Key: \")\n",
    "\n",
    "OPENAI_KEY = \"\"\n",
    "if OPENAI_KEY == \"\":\n",
    "    OPENAI_KEY = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02000905",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Import libraries/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Parse\n",
    "from llama_cloud_services import LlamaParse\n",
    "from copy import deepcopy\n",
    "\n",
    "# Models\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# kg index\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "\n",
    "# Extractors\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    ImplicitPathExtractor,\n",
    "    SimpleLLMPathExtractor,\n",
    ")\n",
    "\n",
    "# Custom retriever\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import NodeWithScore, Document\n",
    "from typing import List\n",
    "\n",
    "# Retrievers\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import BM25Retriever\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
    "\n",
    "# agent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "# from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core.agent.workflow import ToolCallResult, AgentStream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943b7a8",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### Setup Models\n",
    "Here we use gpt-4o and default OpenAI embeddings.\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = OpenAI(model=\"gpt-4o\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "Settings.llm = llm_model\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Best chunk-configuration \n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 200\n",
    "print(Settings.context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df9231",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 1. Parsing (``parse into document``)\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae61b60",
   "metadata": {},
   "source": [
    "##### Load and parse Data with agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = LlamaParse(\n",
    "    parse_mode=\"parse_page_with_agent\",\n",
    "    # model=\"openai-gpt-4-1-mini\",\n",
    "    model=\"anthropic-sonnet-4.0\",\n",
    "    high_res_ocr=True,\n",
    "    adaptive_long_table=True,\n",
    "    outlined_table_extraction=True,\n",
    "    output_tables_as_HTML=True,\n",
    ").load_data(\"../data/bevel_gear.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30997cf",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 2. Splitting (``manual split``)\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971b766",
   "metadata": {},
   "source": [
    "##### Split by page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by page\n",
    "def get_sub_docs(docs):\n",
    "    sub_docs = []\n",
    "    for doc in docs:\n",
    "        page_chunks = doc.text.split(\"\\n---\\n\")\n",
    "        for i, chunk in enumerate(page_chunks):\n",
    "            md = deepcopy(doc.metadata)\n",
    "\n",
    "            # ensure page_number stays correct at page level\n",
    "            md[\"page_number\"] = md.get(\"page_number\", i + 1)\n",
    "\n",
    "            sub_docs.append(\n",
    "                Document(\n",
    "                    text=chunk,\n",
    "                    metadata=md,\n",
    "                )\n",
    "            )\n",
    "    return sub_docs\n",
    "\n",
    "sub_docs = get_sub_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f9a6a",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 3. Indexing\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6fed6",
   "metadata": {},
   "source": [
    "##### 3.1 Vector-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex.from_documents(\n",
    "    sub_docs, \n",
    "    embed_model=embed_model,\n",
    "    vector_store='',  # if not specified, embeddings live in RAM\n",
    "    # vector_store=faiss_store,  # or Pinecone / Weaviate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265243c5",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### 4. Retrieval\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c481113",
   "metadata": {},
   "source": [
    "##### 4.1 Vector retriever (embeddings similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bcccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = base_index.as_retriever(similarity_top_k=10)\n",
    "naive_query_engine = RetrieverQueryEngine(vector_retriever)\n",
    "\n",
    "# Query\n",
    "response = naive_query_engine.query(\n",
    "    \"Worum geht es in dem Dokument? Antworte in 2-3 Sätzen.\"\n",
    "    \"Aus welchem Material besteht das Kegelrad?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e9cb7",
   "metadata": {},
   "source": [
    "##### 4.2 Hybrid retriever (BM25 keyword + vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd495df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever.from_documents(\n",
    "    sub_docs,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "hybrid_retriever = QueryFusionRetriever(\n",
    "    retrievers=[bm25, vector_retriever],\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "hybrid_query_engine = RetrieverQueryEngine.from_args(retriever=hybrid_retriever)\n",
    "\n",
    "# Query\n",
    "response = hybrid_query_engine.query(\n",
    "    \"Worum geht es in dem Dokument? Antworte in 2-3 Sätzen.\"\n",
    "    \"Aus welchem Material besteht das Kegelrad?\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
