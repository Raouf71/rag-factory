{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1f7051",
   "metadata": {},
   "source": [
    "## Demo - Extract with agent \n",
    "---\n",
    "Custom config:\n",
    "* ``Schema alignment``:\n",
    "    * extraction_target= PER_DOC \n",
    "* ``Model settings``: \n",
    "    * extraction_mode= MULTIMODAL (suitable for visually rich documents with a mix of text, simple tables, and images) \n",
    "    * parse_model=GEMINI-2.0-flash (Default model)\n",
    "\n",
    "* ``system_prompt``\n",
    "\n",
    "* ``Metadata extensions``:\n",
    "    * use_reasoning= True\n",
    "    * cite_sources= True\n",
    "    * confidence_scores= True (Confidence scores provide quantitative measures of how confident the system is in the extracted values, helping you identify potentially unreliable extractions.)\n",
    "\n",
    "* ``Advanced options``:\n",
    "    * chunk_mode= PAGE \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd4548",
   "metadata": {},
   "source": [
    "### Provide api-keys manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea49108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"LLAMA_CLOUD_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass(\"Enter your Llama Cloud API Key: \")\n",
    "    os.environ[\"OPENAI_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e279e",
   "metadata": {},
   "source": [
    "### Create instance of extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b030bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud_services import LlamaExtract\n",
    "\n",
    "# Optionally, provide your project id, if not, it will use the 'Default' project\n",
    "llama_extract = LlamaExtract()\n",
    "# llama_extract = LlamaExtract(api_key=\"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b04cf",
   "metadata": {},
   "source": [
    "### Define the data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc6f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class TechnicalSkills(BaseModel):\n",
    "    programming_languages: List[str] = Field(\n",
    "        description=\"The programming languages the candidate is proficient in.\"\n",
    "    )\n",
    "    frameworks: List[str] = Field(\n",
    "        description=\"The tools/frameworks the candidate is proficient in, e.g. React, Django, PyTorch, etc.\"\n",
    "    )\n",
    "    skills: List[str] = Field(\n",
    "        description=\"Other general skills the candidate is proficient in, e.g. Data Engineering, Machine Learning, etc.\"\n",
    "    )\n",
    "\n",
    "class Education(BaseModel):\n",
    "    institution: str = Field(description=\"The institution of the candidate\")\n",
    "    degree: str = Field(description=\"The degree of the candidate\")\n",
    "    start_date: Optional[str] = Field(\n",
    "        default=None, description=\"The start date of the candidate's education\"\n",
    "    )\n",
    "    end_date: Optional[str] = Field(\n",
    "        default=None, description=\"The end date of the candidate's education\"\n",
    "    )\n",
    "\n",
    "class Experience(BaseModel):\n",
    "    company: str = Field(description=\"The name of the company\")\n",
    "    title: str = Field(description=\"The title of the candidate\")\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"The description of the candidate's experience\"\n",
    "    )\n",
    "    start_date: Optional[str] = Field(\n",
    "        default=None, description=\"The start date of the candidate's experience\"\n",
    "    )\n",
    "    end_date: Optional[str] = Field(\n",
    "        default=None, description=\"The end date of the candidate's experience\"\n",
    "    )\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    name: str = Field(description=\"The name of the candidate\")\n",
    "    email: str = Field(description=\"The email address of the candidate\")\n",
    "    links: List[str] = Field(\n",
    "        description=\"The links to the candidate's social media profiles\"\n",
    "    )\n",
    "    experience: List[Experience] = Field(description=\"The candidate's experience\")\n",
    "    education: List[Education] = Field(description=\"The candidate's education\")\n",
    "    technical_skills: TechnicalSkills = Field(\n",
    "        description=\"The candidate's technical skills\"\n",
    "    )\n",
    "    key_accomplishments: str = Field(\n",
    "        description=\"Summarize the candidates highest achievements.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5768ed",
   "metadata": {},
   "source": [
    "### Define extraction configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec407a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud import ExtractConfig, ExtractMode, ChunkMode, ExtractTarget\n",
    "\n",
    "custom_config = ExtractConfig(\n",
    "    \n",
    "    # Schema alignment\n",
    "    extraction_target=ExtractTarget.PER_DOC, \n",
    "    # Model settings\n",
    "    extraction_mode=ExtractMode.MULTIMODAL,         # Required for confidence scores\n",
    "    parse_model=\"gemini-2.0-flash\",                 # Default\n",
    "\n",
    "    # System prompt\n",
    "    system_prompt=\"You are dealing with a professional resume, focus on personal information, contact information and qualifications\",\n",
    "\n",
    "    # Metadata extensions \n",
    "    cite_sources=True,                       \n",
    "    use_reasoning=True,                    \n",
    "    confidence_scores=True,                 \n",
    "\n",
    "    # Advanced options\n",
    "    chunk_mode=ChunkMode.PAGE,                \n",
    "    high_resolution_mode=False,              \n",
    "    invalidate_cache=False,           \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f5e91",
   "metadata": {},
   "source": [
    "### Create extraction Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e910a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Agent exists already ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daghbeji/ragragi/genAI_3D_CAD/llamaindex/llamaindex-venv/lib/python3.12/site-packages/llama_cloud_services/extract/extract.py:141: ExperimentalWarning: `cite_sources`/`confidence_scores` could greatly increase the size of the response, and slow down the extraction. Results will be available in the `extraction_metadata` field for the extraction run.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_cloud.core.api_error import ApiError\n",
    "\n",
    "try:\n",
    "    existing_agent = llama_extract.get_agent(name=\"resume-screening\")\n",
    "    if existing_agent:\n",
    "        print(\"============== Agent exists already ==============\")\n",
    "        llama_extract.delete_agent(existing_agent.id)\n",
    "        print(\"============== Old Agent deleted ==============\")\n",
    "    else:\n",
    "        print(\"============== Creating Agent from scratch ==============\")\n",
    "except ApiError as e:\n",
    "    if e.status_code == 404:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "agent = llama_extract.create_agent(\n",
    "    name=\"resume-screening\", \n",
    "    data_schema=Resume,\n",
    "    config=custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f5579",
   "metadata": {},
   "source": [
    "---\n",
    "### Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fa1f1",
   "metadata": {},
   "source": [
    "#### List the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a0a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExtractionAgent(id=628c02ec-722a-411d-91fb-818ff5b46500, name=resume-screening)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_extract.list_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d896cc6",
   "metadata": {},
   "source": [
    "#### Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f567c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:22<00:00, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Extraction finishied successfully ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resume = agent.extract(\"/home/daghbeji/ragragi/genAI_3D_CAD/llamaindex/data/resumes/ai_researcher.pdf\")\n",
    "print(\"============== Extraction finishied successfully ==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad31d0",
   "metadata": {},
   "source": [
    "#### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32a5636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Dr. Rachel Zhang, Ph.D.',\n",
       " 'email': 'rachel.zhang@email.com',\n",
       " 'links': ['linkedin.com/in/rachelzhang',\n",
       "  'github.com/rzhang-ai',\n",
       "  'scholar.google.com/rachelzhang'],\n",
       " 'experience': [{'company': 'DeepMind',\n",
       "   'title': 'Senior Research Scientist',\n",
       "   'description': 'Lead researcher on large-scale multi-task learning systems, developing novel architectures that improve cross-task generalization by 40%. Pioneered new approach to zero-shot learning using contrastive training, published in NeurIPS 2023. Built and led team of 6 researchers working on foundational ML models. Developed novel regularization techniques for large language models, reducing catastrophic forgetting by 35%.',\n",
       "   'start_date': '2019',\n",
       "   'end_date': None},\n",
       "  {'company': 'Google Research',\n",
       "   'title': 'Research Scientist',\n",
       "   'description': 'Developed probabilistic frameworks for robust ML, published in ICML 2018. Created novel attention mechanisms for computer vision models, improving accuracy by 25%. Led collaboration with Google Brain team on efficient training methods for transformer models. Mentored 4 PhD interns and collaborated with academic institutions.',\n",
       "   'start_date': '2015',\n",
       "   'end_date': '2019'},\n",
       "  {'company': 'Columbia University',\n",
       "   'title': 'Research Assistant Professor',\n",
       "   'description': 'Published seminal work on Bayesian optimization methods (cited 1000+ times). Taught graduate-level courses in Machine Learning and Statistical Learning Theory. Supervised 5 PhD students and 3 MSc students. Secured $500K in research grants for probabilistic ML research.',\n",
       "   'start_date': '2011',\n",
       "   'end_date': '2015'}],\n",
       " 'education': [{'institution': 'Columbia University',\n",
       "   'degree': 'Ph.D. in Computer Science',\n",
       "   'start_date': '2007',\n",
       "   'end_date': '2011'},\n",
       "  {'institution': 'Stanford University',\n",
       "   'degree': 'M.S. in Computer Science',\n",
       "   'start_date': '2005',\n",
       "   'end_date': '2007'}],\n",
       " 'technical_skills': {'programming_languages': ['Python',\n",
       "   'C++',\n",
       "   'Julia',\n",
       "   'CUDA'],\n",
       "  'frameworks': ['PyTorch', 'TensorFlow', 'JAX', 'Ray'],\n",
       "  'skills': ['Deep Learning',\n",
       "   'Reinforcement Learning',\n",
       "   'Probabilistic Models',\n",
       "   'Multi-Task Learning',\n",
       "   'Zero-Shot Learning',\n",
       "   'Neural Architecture Search',\n",
       "   'Git & Version Control',\n",
       "   'Docker & Kubernetes',\n",
       "   'Cloud Platforms (AWS, GCP)',\n",
       "   'Research Leadership',\n",
       "   'Technical Writing',\n",
       "   'Team Mentoring']},\n",
       " 'key_accomplishments': 'Recipient of NSF CAREER Award, Google Faculty Research Award, Amazon Research Award, and MIT TR35 (35 under 35). Published 25+ peer-reviewed papers (NeurIPS, ICML, ICLR), h-index 32, 3 best paper awards, 10+ patents, and secured $500K+ in research grants. Authored high-impact research cited over 1000 times.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5578fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'field_metadata': {'name': {'reasoning': 'VERBATIM EXTRACTION',\n",
       "   'parsing_confidence': 0.995353622168994,\n",
       "   'extraction_confidence': 0.9801656136732345,\n",
       "   'confidence': 0.9756113938951488,\n",
       "   'citation': [{'page': 1, 'matching_text': 'Rachel Zhang, Ph.D.'}]},\n",
       "  'email': {'reasoning': 'VERBATIM EXTRACTION',\n",
       "   'parsing_confidence': 0.995353622168994,\n",
       "   'extraction_confidence': 0.9999999081293959,\n",
       "   'confidence': 0.9953535307252555,\n",
       "   'citation': [{'page': 1,\n",
       "     'matching_text': 'New York City Area | rachel.zhang@email.com | (555) 123-4567'}]},\n",
       "  'links': [{'reasoning': 'VERBATIM EXTRACTION',\n",
       "    'parsing_confidence': 0.995353622168994,\n",
       "    'extraction_confidence': 0.9990411213314138,\n",
       "    'confidence': 0.9943991988129961,\n",
       "    'citation': [{'page': 1,\n",
       "      'matching_text': 'linkedin.com/in/rachelzhang | github.com/rzhang-ai | scholar.google.com/rachelzhang'}]},\n",
       "   {'reasoning': 'VERBATIM EXTRACTION',\n",
       "    'parsing_confidence': 0.995353622168994,\n",
       "    'extraction_confidence': 1.0,\n",
       "    'confidence': 0.995353622168994,\n",
       "    'citation': [{'page': 1,\n",
       "      'matching_text': 'linkedin.com/in/rachelzhang | github.com/rzhang-ai | scholar.google.com/rachelzhang'}]},\n",
       "   {'reasoning': 'VERBATIM EXTRACTION',\n",
       "    'parsing_confidence': 0.995353622168994,\n",
       "    'extraction_confidence': 1.0,\n",
       "    'confidence': 0.995353622168994,\n",
       "    'citation': [{'page': 1,\n",
       "      'matching_text': 'linkedin.com/in/rachelzhang | github.com/rzhang-ai | scholar.google.com/rachelzhang'}]}],\n",
       "  'experience': [{'company': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': 'DeepMind'}]},\n",
       "    'title': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': 'Senior Research Scientist'}]},\n",
       "    'description': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.997032028703088,\n",
       "     'confidence': 0.9923994411881191,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Lead researcher on large-scale multi-task learning systems, developing novel architectures that improve cross-task generalization by 40%'}]},\n",
       "    'start_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '2015 - 2019'}]},\n",
       "    'end_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'confidence': 0.995353622168994},\n",
       "    'reasoning': 'VERBATIM EXTRACTION'},\n",
       "   {'company': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': 'Google Research'}]},\n",
       "    'title': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': 'Research Scientist'}]},\n",
       "    'description': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999627864180133,\n",
       "     'confidence': 0.9953165814953697,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Led collaboration with Google Brain team on efficient training methods for transformer models'}]},\n",
       "    'start_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '2015 - 2019'}]},\n",
       "    'end_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '2015 - 2019'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION'},\n",
       "   {'company': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': 'Columbia University'}]},\n",
       "    'title': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': 'Research Assistant Professor'}]},\n",
       "    'description': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999692001067443,\n",
       "     'confidence': 0.9953229653836796,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '- Published seminal work on Bayesian optimization methods (cited 1000+ times)'}]},\n",
       "    'start_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '2011-2015'}]},\n",
       "    'end_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '2011-2015'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION'}],\n",
       "  'education': [{'institution': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': 'Columbia University'}]},\n",
       "    'degree': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999997566569819,\n",
       "     'confidence': 0.9953533799566395,\n",
       "     'citation': [{'page': 2, 'matching_text': 'Ph.D. in Computer Science'}]},\n",
       "    'start_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '2007-2011'}]},\n",
       "    'end_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '2011-2015'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION'},\n",
       "   {'institution': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': 'Stanford University'}]},\n",
       "    'degree': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999999478639471,\n",
       "     'confidence': 0.9953535702751849,\n",
       "     'citation': [{'page': 2, 'matching_text': 'M.S. in Computer Science'}]},\n",
       "    'start_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '2005-2007'}]},\n",
       "    'end_date': {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '2007-2011'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION'}],\n",
       "  'technical_skills': {'programming_languages': [{'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- Python'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- C++'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- Julia'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- CUDA'}]}],\n",
       "   'frameworks': [{'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- PyTorch'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- TensorFlow'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- JAX'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1, 'matching_text': '- Ray'}]}],\n",
       "   'skills': [{'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9998920984736507,\n",
       "     'confidence': 0.9952462219939047,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '\"Probabilistic Frameworks for Robust Deep Learning\"'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999964052943632,\n",
       "     'confidence': 0.9953500441657178,\n",
       "     'citation': [{'page': 1, 'matching_text': '- Reinforcement Learning'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999970721109664,\n",
       "     'confidence': 0.9953507078840392,\n",
       "     'citation': [{'page': 1, 'matching_text': '- Probabilistic Models'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999982641448073,\n",
       "     'confidence': 0.9953518943792404,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '\"Scalable Multi-Task Learning with Efficient Cross-Task Transfer\"'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999997727913668,\n",
       "     'confidence': 0.995353396016058,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '\"Zero-Shot Learning through Contrastive Optimization\"'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Neural Architecture Search'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9801515471601484,\n",
       "     'confidence': 0.9755973927403973,\n",
       "     'citation': [{'page': 2, 'matching_text': '- Git & Version Control'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9997633851209219,\n",
       "     'confidence': 0.9951181066920446,\n",
       "     'citation': [{'page': 2, 'matching_text': '- Docker & Kubernetes'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9983782732558987,\n",
       "     'confidence': 0.9937394305800844,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '- Cloud Platforms (AWS, GCP)'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9995421956554947,\n",
       "     'confidence': 0.994897944956446,\n",
       "     'citation': [{'page': 2, 'matching_text': '- Research Leadership'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 0.9999981151405137,\n",
       "     'confidence': 0.995351746067277,\n",
       "     'citation': [{'page': 2, 'matching_text': '- Technical Writing'}]},\n",
       "    {'parsing_confidence': 0.995353622168994,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.995353622168994,\n",
       "     'citation': [{'page': 2, 'matching_text': '- Team Mentoring'}]}],\n",
       "   'reasoning': 'VERBATIM EXTRACTION'},\n",
       "  'key_accomplishments': {'reasoning': 'Summary synthesized from grants/awards and research impact sections; all accomplishments directly listed.',\n",
       "   'parsing_confidence': 0.995353622168994,\n",
       "   'extraction_confidence': 0.7371425461924773,\n",
       "   'confidence': 0.7337175034075573}},\n",
       " 'usage': {'num_pages_extracted': 2,\n",
       "  'num_document_tokens': 847,\n",
       "  'num_output_tokens': 1289},\n",
       " 'parse_job_id': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume.extraction_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e81e2",
   "metadata": {},
   "source": [
    "#### Save extraction template for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1aa18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Saved extraction agent's schema and config to the database ==============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'additionalProperties': False,\n",
       " 'properties': {'name': {'description': 'The name of the candidate',\n",
       "   'type': 'string'},\n",
       "  'email': {'description': 'The email address of the candidate',\n",
       "   'type': 'string'},\n",
       "  'links': {'description': \"The links to the candidate's social media profiles\",\n",
       "   'items': {'type': 'string'},\n",
       "   'type': 'array'},\n",
       "  'experience': {'description': \"The candidate's experience\",\n",
       "   'items': {'additionalProperties': False,\n",
       "    'properties': {'company': {'description': 'The name of the company',\n",
       "      'type': 'string'},\n",
       "     'title': {'description': 'The title of the candidate', 'type': 'string'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'description': \"The description of the candidate's experience\"},\n",
       "     'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'description': \"The start date of the candidate's experience\"},\n",
       "     'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'description': \"The end date of the candidate's experience\"}},\n",
       "    'required': ['company', 'title', 'description', 'start_date', 'end_date'],\n",
       "    'type': 'object'},\n",
       "   'type': 'array'},\n",
       "  'education': {'description': \"The candidate's education\",\n",
       "   'items': {'additionalProperties': False,\n",
       "    'properties': {'institution': {'description': 'The institution of the candidate',\n",
       "      'type': 'string'},\n",
       "     'degree': {'description': 'The degree of the candidate',\n",
       "      'type': 'string'},\n",
       "     'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'description': \"The start date of the candidate's education\"},\n",
       "     'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'description': \"The end date of the candidate's education\"}},\n",
       "    'required': ['institution', 'degree', 'start_date', 'end_date'],\n",
       "    'type': 'object'},\n",
       "   'type': 'array'},\n",
       "  'technical_skills': {'additionalProperties': False,\n",
       "   'description': \"The candidate's technical skills\",\n",
       "   'properties': {'programming_languages': {'description': 'The programming languages the candidate is proficient in.',\n",
       "     'items': {'type': 'string'},\n",
       "     'type': 'array'},\n",
       "    'frameworks': {'description': 'The tools/frameworks the candidate is proficient in, e.g. React, Django, PyTorch, etc.',\n",
       "     'items': {'type': 'string'},\n",
       "     'type': 'array'},\n",
       "    'skills': {'description': 'Other general skills the candidate is proficient in, e.g. Data Engineering, Machine Learning, etc.',\n",
       "     'items': {'type': 'string'},\n",
       "     'type': 'array'}},\n",
       "   'required': ['programming_languages', 'frameworks', 'skills'],\n",
       "   'type': 'object'},\n",
       "  'key_accomplishments': {'description': 'Summarize the candidates highest achievements.',\n",
       "   'type': 'string'}},\n",
       " 'required': ['name',\n",
       "  'email',\n",
       "  'links',\n",
       "  'experience',\n",
       "  'education',\n",
       "  'technical_skills',\n",
       "  'key_accomplishments'],\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.save()\n",
    "print(\"============== Saved extraction agent's schema and config to the database ==============\")\n",
    "\n",
    "agent = llama_extract.get_agent(\"resume-screening\")\n",
    "agent.data_schema  # Latest schema should be returned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b24a5",
   "metadata": {},
   "source": [
    "### Test extracted data_schema on my personal resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15435ff8",
   "metadata": {},
   "source": [
    "#### complex CV (3 pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ae19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Agent exists already ==============\n",
      "{'additionalProperties': False, 'properties': {'name': {'description': 'The name of the candidate', 'type': 'string'}, 'email': {'description': 'The email address of the candidate', 'type': 'string'}, 'links': {'description': \"The links to the candidate's social media profiles\", 'items': {'type': 'string'}, 'type': 'array'}, 'experience': {'description': \"The candidate's experience\", 'items': {'additionalProperties': False, 'properties': {'company': {'description': 'The name of the company', 'type': 'string'}, 'title': {'description': 'The title of the candidate', 'type': 'string'}, 'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': \"The description of the candidate's experience\"}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': \"The start date of the candidate's experience\"}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': \"The end date of the candidate's experience\"}}, 'required': ['company', 'title', 'description', 'start_date', 'end_date'], 'type': 'object'}, 'type': 'array'}, 'education': {'description': \"The candidate's education\", 'items': {'additionalProperties': False, 'properties': {'institution': {'description': 'The institution of the candidate', 'type': 'string'}, 'degree': {'description': 'The degree of the candidate', 'type': 'string'}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': \"The start date of the candidate's education\"}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': \"The end date of the candidate's education\"}}, 'required': ['institution', 'degree', 'start_date', 'end_date'], 'type': 'object'}, 'type': 'array'}, 'technical_skills': {'additionalProperties': False, 'description': \"The candidate's technical skills\", 'properties': {'programming_languages': {'description': 'The programming languages the candidate is proficient in.', 'items': {'type': 'string'}, 'type': 'array'}, 'frameworks': {'description': 'The tools/frameworks the candidate is proficient in, e.g. React, Django, PyTorch, etc.', 'items': {'type': 'string'}, 'type': 'array'}, 'skills': {'description': 'Other general skills the candidate is proficient in, e.g. Data Engineering, Machine Learning, etc.', 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['programming_languages', 'frameworks', 'skills'], 'type': 'object'}, 'key_accomplishments': {'description': 'Summarize the candidates highest achievements.', 'type': 'string'}}, 'required': ['name', 'email', 'links', 'experience', 'education', 'technical_skills', 'key_accomplishments'], 'type': 'object'}\n",
      "priority=None extraction_target=<ExtractTarget.PER_DOC: 'PER_DOC'> extraction_mode=<ExtractMode.MULTIMODAL: 'MULTIMODAL'> multimodal_fast_mode=False system_prompt='Focus on the most recent financial data' use_reasoning=True cite_sources=True confidence_scores=True chunk_mode=<DocumentChunkMode.PAGE: 'PAGE'> high_resolution_mode=False invalidate_cache=False page_range=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
      "Extracting files: 100%|██████████| 1/1 [00:33<00:00, 33.13s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_cloud.core.api_error import ApiError\n",
    "\n",
    "try:\n",
    "    existing_agent = llama_extract.get_agent(name=\"resume-screening\")\n",
    "    if existing_agent:\n",
    "        print(\"============== Agent exists already ==============\")\n",
    "        print(existing_agent.data_schema)\n",
    "        print(existing_agent.config)\n",
    "\n",
    "        new_cv_path = \"/home/daghbeji/ragragi/genAI_3D_CAD/llamaindex/data/resumes/Lebenslauf_complex.pdf\"\n",
    "        my_resume = existing_agent.extract(new_cv_path)\n",
    "\n",
    "except ApiError as e:\n",
    "    if e.status_code == 404:\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecb2c9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Abderraouf Ayadi',\n",
       " 'email': 'ayadi_raouf@outlook.com',\n",
       " 'links': ['https://www.linkedin.com/in/raouf-ayadi-a0a142223/'],\n",
       " 'experience': [{'company': 'Leibniz Universität Hannover | Institut für Produktentwicklung und Gerätebau (iPeG)',\n",
       "   'title': 'WISSENSCHAFTLICHE HILFSKRAFT',\n",
       "   'description': 'Aufbau eines RAG-basierten (Retrieval-Augmented Generation) Systems zum effizienten Durchsuchen von Nachschlagewerken zur mechanischen Konstruktionstechnik. Testen und Bewerten vortrainierter LLM-Modelle auf dem neuesten Stand der Technik zur Generierung parametrischer 3D-CAD-Modelle.',\n",
       "   'start_date': '11.2025',\n",
       "   'end_date': '12.2025'},\n",
       "  {'company': 'Leibniz Universität Hannover | Institut für Montagetechnik und Industrierobotik (Match)',\n",
       "   'title': 'WISSENSCHAFTLICHE HILFSKRAFT',\n",
       "   'description': 'Entwicklung eines ROS-basierten Simulations- und Steuerungsframeworks für Multikopter, mit Integration von PX4 und MAVROS. Integration, Test und Benchmarking moderner SLAM-Algorithmen zur Indoor-Kartierung industrieller Umgebungen.',\n",
       "   'start_date': '07.2025',\n",
       "   'end_date': '09.2025'},\n",
       "  {'company': 'IPH - Institut für Integrierte Produktion Hannover gGmbH',\n",
       "   'title': 'WISSENSCHAFTLICHE HILFSKRAFT',\n",
       "   'description': 'Untersuchung aufgabenspezifischer Entscheidungsalgorithmen und Lernprinzipien für autonome Multikopterexploration in industriellen Umgebungen. Programmierung und Training eines Deep-Reinforcement-Learning-Agenten zur autonomen Exploration von Produktionsumgebungen.',\n",
       "   'start_date': '05.2025',\n",
       "   'end_date': '07.2025'},\n",
       "  {'company': 'IPH - Institut für Integrierte Produktion Hannover gGmbH',\n",
       "   'title': 'PRAKTIKUM',\n",
       "   'description': 'Entwurf und Implementierung einer benutzerdefinierten voxelbasierten Simulations-Engine einschließlich Sensormodellen, Kartierung und Systemschnittstellen für autonome Multikopter. Implementierung von Algorithmen zur Pfadplanung. Testen und Validieren der Softwarequalität.',\n",
       "   'start_date': '02.2024',\n",
       "   'end_date': '04.2024'},\n",
       "  {'company': 'Leibniz Universität Hannover | Geodätisches Institut Hannover (GIH)',\n",
       "   'title': 'STUDENTISCHE HILFSKRAFT',\n",
       "   'description': 'Kalibrierung und Georeferenzierung von Messsensoren. Implementierung von Segmentierungsalgorithmen für Mustererkennung in 3D-Punktwolken.',\n",
       "   'start_date': '02.2023',\n",
       "   'end_date': '11.2023'}],\n",
       " 'education': [{'institution': 'Leibniz Universität Hannover',\n",
       "   'degree': 'Master of Science Mechatronik und Robotik',\n",
       "   'start_date': '10.2022',\n",
       "   'end_date': '09.2025'},\n",
       "  {'institution': 'Leibniz Universität Hannover',\n",
       "   'degree': 'Bachelor of Science Mechatronik',\n",
       "   'start_date': '10.2016',\n",
       "   'end_date': '09.2022'},\n",
       "  {'institution': 'Elite Gymnasium Sousse',\n",
       "   'degree': 'Technisches Abitur',\n",
       "   'start_date': '09.2011',\n",
       "   'end_date': '06.2015'}],\n",
       " 'technical_skills': {'programming_languages': ['C',\n",
       "   'C++',\n",
       "   'Matlab',\n",
       "   'Python'],\n",
       "  'frameworks': ['ROS',\n",
       "   'TensorFlow',\n",
       "   'PyTorch',\n",
       "   'Keras',\n",
       "   'Pandas',\n",
       "   'NumPy',\n",
       "   'Matplotlib',\n",
       "   'Scikit-Learn',\n",
       "   'Open3D',\n",
       "   'Pygame',\n",
       "   'Tkinter',\n",
       "   'openMP',\n",
       "   'TBB',\n",
       "   'Gprof',\n",
       "   'MinkowskiEngine',\n",
       "   'cuDNN',\n",
       "   'Thrust',\n",
       "   'TensorRT',\n",
       "   'smolagents',\n",
       "   'LangChain Agents',\n",
       "   'LangChain',\n",
       "   'LlamaIndex',\n",
       "   'Hugging Face Transformers',\n",
       "   'PX4',\n",
       "   'MAVROS'],\n",
       "  'skills': ['Maschinelles Lernen / KI',\n",
       "   'Convolutional Neural Networks (Dense and Sparse)',\n",
       "   'Clustering (K-means, Mean-Shift, DBSCAN, Hierarchisches Clustering)',\n",
       "   'Principal Component Analysis (PCA)',\n",
       "   'CUDA',\n",
       "   'Vektorsuche: ChromaDB, Qdrant, Elasticsearch',\n",
       "   'Knowledge Graphs: Neo4j',\n",
       "   'RAG und Knowledge-Systeme',\n",
       "   'Docling',\n",
       "   'MinerU',\n",
       "   'PyPDF2',\n",
       "   'lama-Parse',\n",
       "   'DeepSeek-OCR',\n",
       "   'Chunking, Embeddings, Indexing, Retrieval, Reranking',\n",
       "   'RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RAG',\n",
       "   'ReAct, Tool-Calling, Reasoning Agents',\n",
       "   'Text und Vision-Language Models: OpenAI, Claude, Llama, Qwen',\n",
       "   'Embeddings: text-embedding-3, bge-m3, nomic-embed-text',\n",
       "   'Reranking: Jina Reranker, Cohere Rerank',\n",
       "   'Ollama',\n",
       "   'PowerPoint',\n",
       "   'Excel',\n",
       "   'Word',\n",
       "   'Autodesk Inventor',\n",
       "   'SolidWorks',\n",
       "   'FreeCAD',\n",
       "   'Docker',\n",
       "   'Git',\n",
       "   'GitHub',\n",
       "   'GitLab',\n",
       "   'Windows',\n",
       "   'Linux (Ubuntu)']},\n",
       " 'key_accomplishments': 'Recipient of DAAD and Tunisian Government scholarships for academic excellence. Led and contributed to EU projects on digital twins, autonomous robotics, and deep learning-based industrial automation (AIMS5.0). Developed advanced ML and simulation toolkits for industrial environments.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_resume.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e68a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'field_metadata': {'name': {'reasoning': 'VERBATIM EXTRACTION.',\n",
       "   'parsing_confidence': 0.8618428227656375,\n",
       "   'extraction_confidence': 0.9669882941743665,\n",
       "   'confidence': 0.8333919210325647,\n",
       "   'citation': [{'page': 1, 'matching_text': '# M. Sc. Abderraouf Ayadi'}]},\n",
       "  'email': {'reasoning': 'VERBATIM EXTRACTION.',\n",
       "   'parsing_confidence': 0.8618428227656375,\n",
       "   'extraction_confidence': 0.9999999757984191,\n",
       "   'confidence': 0.8618428019076787,\n",
       "   'citation': [{'page': 1, 'matching_text': 'ayadi_raouf@outlook.com'}]},\n",
       "  'links': [{'reasoning': 'VERBATIM EXTRACTION.',\n",
       "    'parsing_confidence': 0.8618428227656375,\n",
       "    'extraction_confidence': 1.0,\n",
       "    'confidence': 0.8618428227656375,\n",
       "    'citation': [{'page': 1,\n",
       "      'matching_text': 'https://www.linkedin.com/in/raouf-ayadi-a0a142223/'}]}],\n",
       "  'experience': [{'company': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999494262530574,\n",
       "     'confidence': 0.8617992361448147,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '11.2025-12.2025 Leibniz Universität Hannover | Institut für Produktentwicklung und Gerätebau (iPeG), WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'title': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8962148459440589,\n",
       "     'confidence': 0.7723963326328986,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'description': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.992153444037416,\n",
       "     'confidence': 0.8550803248258556,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Testen und Bewerten vortrainierter LLM-Modelle auf dem neuesten Stand der Technik zur Generierung parametrischer 3D-CAD-Modelle.'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9992058870740004,\n",
       "     'confidence': 0.8611584222398994,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '11.2025-12.2025 Leibniz Universität Hannover | Institut für Produktentwicklung und Gerätebau (iPeG), WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '11.2025-12.2025 Leibniz Universität Hannover | Institut für Produktentwicklung und Gerätebau (iPeG), WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'},\n",
       "   {'company': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9965920167413173,\n",
       "     'confidence': 0.8589056768540363},\n",
       "    'title': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999999739319732,\n",
       "     'confidence': 0.8618428002990957,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'description': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9687407526226177,\n",
       "     'confidence': 0.834902264768385,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Entwicklung eines ROS-basierten Simulations- und Steuerungsframeworks für Multikopter, mit der Integration von PX4 und MAVROS.'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '07.2025-09.2025 Leibniz Universität Hannover | Institut für Montagetechnik und Industrier- obotik (Match), WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'},\n",
       "   {'company': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999758556701996,\n",
       "     'confidence': 0.8618220141482886,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'title': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999997628577318,\n",
       "     'confidence': 0.8618426183862757,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'description': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9427836932626935,\n",
       "     'confidence': 0.8125313594589327},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '05.2025-07.2025 IPH - Institut für Integrierte Produktion Hannover gGmbH, WISSENSCHAFTLICHE HILFSKRAFT'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'},\n",
       "   {'company': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999993422647334,\n",
       "     'confidence': 0.8618422559012188,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2024-04.2024 IPH - Institut für Integrierte Produktion Hannover gGmbH, PRAKTIKUM'}]},\n",
       "    'title': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999801111040768,\n",
       "     'confidence': 0.8618256816634333,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2024-04.2024 IPH - Institut für Integrierte Produktion Hannover gGmbH, PRAKTIKUM'}]},\n",
       "    'description': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.895338621612628,\n",
       "     'confidence': 0.7716411649817223,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '- Entwurf und Implementierung einer benutzerdefinierten voxelbasierten Simulations-Engine einschließlich Sensormodellen, Kartierung und Systemschnittstellen, für autonome Multikopter.'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2024-04.2024 IPH - Institut für Integrierte Produktion Hannover gGmbH, PRAKTIKUM'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2024-04.2024 IPH - Institut für Integrierte Produktion Hannover gGmbH, PRAKTIKUM'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'},\n",
       "   {'company': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999977991336148,\n",
       "     'confidence': 0.8618409259647395,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2023-11.2023 Leibniz Universität Hannover | Geodätisches Institut Hannover (GIH), STUDENTISCHE HILFSKRAFT'}]},\n",
       "    'title': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999821937203759,\n",
       "     'confidence': 0.8618274765513433,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2023-11.2023 Leibniz Universität Hannover | Geodätisches Institut Hannover (GIH), STUDENTISCHE HILFSKRAFT'}]},\n",
       "    'description': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8595613155940214,\n",
       "     'confidence': 0.7408067505716964,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '- Implementierung von Segmentierungsalgorithmen zur Mustererkennung in 3D-Punktwolken.'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2023-11.2023 Leibniz Universität Hannover | Geodätisches Institut Hannover (GIH), STUDENTISCHE HILFSKRAFT'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '02.2023-11.2023 Leibniz Universität Hannover | Geodätisches Institut Hannover (GIH), STUDENTISCHE HILFSKRAFT'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'}],\n",
       "  'education': [{'institution': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2016-09.2022 Leibniz Universität Hannover, BACHELOR OF SCIENCE MECHATRONIK'}]},\n",
       "    'degree': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9914577490770158,\n",
       "     'confidence': 0.8544807451174005,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2022-09.2025 Leibniz Universität Hannover, MASTER OF SCIENCE MECHATRONIK UND ROBOTIK'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2022-09.2025 Leibniz Universität Hannover, MASTER OF SCIENCE MECHATRONIK UND ROBOTIK'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2022-09.2025 Leibniz Universität Hannover, MASTER OF SCIENCE MECHATRONIK UND ROBOTIK'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'},\n",
       "   {'institution': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2016-09.2022 Leibniz Universität Hannover, BACHELOR OF SCIENCE MECHATRONIK'}]},\n",
       "    'degree': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999998829649659,\n",
       "     'confidence': 0.8618427218998334,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2016-09.2022 Leibniz Universität Hannover, BACHELOR OF SCIENCE MECHATRONIK'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2016-09.2022 Leibniz Universität Hannover, BACHELOR OF SCIENCE MECHATRONIK'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '10.2016-09.2022 Leibniz Universität Hannover, BACHELOR OF SCIENCE MECHATRONIK'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'},\n",
       "   {'institution': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '09.2011-06.2015 Elite Gymnasium Sousse, TESCHNISCHES ABITUR'}]},\n",
       "    'degree': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999549671777923,\n",
       "     'confidence': 0.8618040115510289,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Vollstipendium für exzellente Leistungen im nationalen Abitur für ein Studium in Deutschland.'}]},\n",
       "    'start_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '09.2011-06.2015 Elite Gymnasium Sousse, TESCHNISCHES ABITUR'}]},\n",
       "    'end_date': {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 2,\n",
       "       'matching_text': '09.2011-06.2015 Elite Gymnasium Sousse, TESCHNISCHES ABITUR'}]},\n",
       "    'reasoning': 'VERBATIM EXTRACTION.'}],\n",
       "  'technical_skills': {'programming_languages': [{'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999997839900294,\n",
       "     'confidence': 0.8618426365989947,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9969920829282566,\n",
       "     'confidence': 0.8592504710258813,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]}],\n",
       "   'frameworks': [{'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.028682574200833016,\n",
       "     'confidence': 0.024719870713430774,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Entwicklung eines ROS-basierten Simulations- und Steuerungsframeworks für Multikopter, mit der Integration von PX4 und MAVROS.'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8024215481181292,\n",
       "     'confidence': 0.6915612520781013,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999971019118378,\n",
       "     'confidence': 0.8618403250691552,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999994859809547,\n",
       "     'confidence': 0.8618423797620125,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9966951130388256,\n",
       "     'confidence': 0.8589945296580976,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999988899631284,\n",
       "     'confidence': 0.8618418660883267,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.999936455329019,\n",
       "     'confidence': 0.8617880572470276,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9997711880549721,\n",
       "     'confidence': 0.8616456228330521,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.388566040548236,\n",
       "     'confidence': 0.3348828532169589,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.7735263448005266,\n",
       "     'confidence': 0.6666581284864717,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999998435918493,\n",
       "     'confidence': 0.8618426879663954,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.42081344895891687,\n",
       "     'confidence': 0.3626750507084964,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999999031936799,\n",
       "     'confidence': 0.8618427393338054,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9985137107849912,\n",
       "     'confidence': 0.8605618750731282,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Programmiersprachen C, C++ (openMP, TBB, Gprof), Matlab, Python (TensorFlow, PyTorch, Keras, Pandas, NumPy, Matplotlib, Scikit-Learn, Pygame, Tkinter, Open3D)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8330332105440825,\n",
       "     'confidence': 0.7179436936328337,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Maschinelles Lernen / KI Convolutional Neural Networks (CNNs): Dense and Sparse (MinkowskiEngine), Clustering (K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PC...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.7983958205428413,\n",
       "     'confidence': 0.6880917076609298,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...(K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PCA), CUDA (cuDNN, Thrust, TensorRT)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999693279252895,\n",
       "     'confidence': 0.861816388258189,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...s, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PCA), CUDA (cuDNN, Thrust, TensorRT)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999997839900294,\n",
       "     'confidence': 0.8618426365989947,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PCA), CUDA (cuDNN, Thrust, TensorRT)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.15236171823692746,\n",
       "     'confidence': 0.13131185332673628,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Agentische Systeme und Tool-Use ReAct, Tool-Calling, Reasoning Agents Frameworks: smolagents, LangChain Agents'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9347751809188076,\n",
       "     'confidence': 0.8056292805743247,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Agentische Systeme und Tool-Use ReAct, Tool-Calling, Reasoning Agents Frameworks: smolagents, LangChain Agents'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9853303529019164,\n",
       "     'confidence': 0.8491998927016494,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'LLM Frameworks und APIs LangChain, LlamaIndex, Hugging Face Transformers'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999283574090243,\n",
       "     'confidence': 0.8617810781128008,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'LLM Frameworks und APIs LangChain, LlamaIndex, Hugging Face Transformers'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.999904231691876,\n",
       "     'confidence': 0.8617602855366324,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'LLM Frameworks und APIs LangChain, LlamaIndex, Hugging Face Transformers'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.4988760179933183,\n",
       "     'confidence': 0.4299527155574424,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Entwicklung eines ROS-basierten Simulations- und Steuerungsframeworks für Multikopter, mit der Integration von PX4 und MAVROS.'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.999999711986721,\n",
       "     'confidence': 0.8618425745434601,\n",
       "     'citation': [{'page': 1,\n",
       "       'matching_text': '- Entwicklung eines ROS-basierten Simulations- und Steuerungsframeworks für Multikopter, mit der Integration von PX4 und MAVROS.'}]}],\n",
       "   'skills': [{'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.5285882592460764,\n",
       "     'confidence': 0.4555599974294131,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Maschinelles Lernen / KI Convolutional Neural Networks (CNNs): Dense and Sparse (MinkowskiEngine), Clustering (K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PC...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.6664530277119343,\n",
       "     'confidence': 0.574377758643959,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Maschinelles Lernen / KI Convolutional Neural Networks (CNNs): Dense and Sparse (MinkowskiEngine), Clustering (K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PC...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.7479529816834273,\n",
       "     'confidence': 0.6446179090300201,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Maschinelles Lernen / KI Convolutional Neural Networks (CNNs): Dense and Sparse (MinkowskiEngine), Clustering (K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PC...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9732902468209891,\n",
       "     'confidence': 0.8388232136904653,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...and Sparse (MinkowskiEngine), Clustering (K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PCA), CUDA (cuDNN, Thrust, TensorRT)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8227941907421406,\n",
       "     'confidence': 0.7091192679043747,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...ering (K-means, Mean-Shift, Hierarchisches Clustering, DBSCAN), Principal Component Analysis (PCA), CUDA (cuDNN, Thrust, TensorRT)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.5580380397205358,\n",
       "     'confidence': 0.4809410793633495,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Vektorsuche und Wissensrepräsentation Vector Stores: ChromaDB, Qdrant, Elasticsearch Knowledge Graphs: Neo4j'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9799184399889227,\n",
       "     'confidence': 0.8445356744001531,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Vektorsuche und Wissensrepräsentation Vector Stores: ChromaDB, Qdrant, Elasticsearch Knowledge Graphs: Neo4j'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.7135542076431148,\n",
       "     'confidence': 0.61497157251144,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'RAG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RA...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.21726488349519207,\n",
       "     'confidence': 0.18724818047934372,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'RAG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RA...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9994387034811497,\n",
       "     'confidence': 0.8613590733894231,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'RAG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RA...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9997980822963468,\n",
       "     'confidence': 0.8616688014419547,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'RAG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RA...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999234058882567,\n",
       "     'confidence': 0.8617768106801654,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'RAG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RA...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999669569569626,\n",
       "     'confidence': 0.8618143448561534,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'RAG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RA...'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8888554575641683,\n",
       "     'confidence': 0.7660536965777451,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...AG und Knowledge-Systeme Parsing und Extraction (Docling, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RAG'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9458176280491998,\n",
       "     'confidence': 0.8151461343794222,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': '...ing, MinerU, PyPDF2, lama-Parse, DeepSeek-OCR) Chunking, Embeddings, Indexing, Retrieval, Reranking RAG-Patterns: Hybrid RAG, GraphRAG, Agentic RAG'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.7575315361609433,\n",
       "     'confidence': 0.652873117458937,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Agentische Systeme und Tool-Use ReAct, Tool-Calling, Reasoning Agents Frameworks: smolagents, LangChain Agents'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9616570467547351,\n",
       "     'confidence': 0.8287972237075675,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Modelle und Inferenz Text und Vision-Language Models: OpenAI, Claude, Llama, Qwen Embeddings: text-embedding-3, bge-m3, nomic-embed-text Reranking: Jina Reranker, Cohere Rerank Lokales Hosting: Ollama'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.998133694847138,\n",
       "     'confidence': 0.8602343610645529,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Modelle und Inferenz Text und Vision-Language Models: OpenAI, Claude, Llama, Qwen Embeddings: text-embedding-3, bge-m3, nomic-embed-text Reranking: Jina Reranker, Cohere Rerank Lokales Hosting: Ollama'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9994242277905974,\n",
       "     'confidence': 0.8613465976194159,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Modelle und Inferenz Text und Vision-Language Models: OpenAI, Claude, Llama, Qwen Embeddings: text-embedding-3, bge-m3, nomic-embed-text Reranking: Jina Reranker, Cohere Rerank Lokales Hosting: Ollama'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.5095220075120914,\n",
       "     'confidence': 0.4391278852154352,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Modelle und Inferenz Text und Vision-Language Models: OpenAI, Claude, Llama, Qwen Embeddings: text-embedding-3, bge-m3, nomic-embed-text Reranking: Jina Reranker, Cohere Rerank Lokales Hosting: Ollama'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.8788302422664951,\n",
       "     'confidence': 0.7574135367267651,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999883629029224,\n",
       "     'confidence': 0.8618327934170433,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999899125340943,\n",
       "     'confidence': 0.8618341289555468,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999430082586577,\n",
       "     'confidence': 0.8617937048424047,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999997467855445,\n",
       "     'confidence': 0.8618426045345764,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999998435918493,\n",
       "     'confidence': 0.8618426879663954,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9998410507423425,\n",
       "     'confidence': 0.8617058334887415,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Software und Werkzeuge PowerPoint, Excel, Word, Autodesk Inventor, SolidWorks, FreeCAD, Docker'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9822521459947888,\n",
       "     'confidence': 0.8465469621717538,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Version Control Git, GitHub, GitLab'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9999420538897673,\n",
       "     'confidence': 0.8617928823264263,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Version Control Git, GitHub, GitLab'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 1.0,\n",
       "     'confidence': 0.8618428227656375,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Version Control Git, GitHub, GitLab'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.998488661974386,\n",
       "     'confidence': 0.8605402869354893,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Betriebssysteme Windows, Linux (Ubuntu)'}]},\n",
       "    {'parsing_confidence': 0.8618428227656375,\n",
       "     'extraction_confidence': 0.9993251379533589,\n",
       "     'confidence': 0.8612611977543829,\n",
       "     'citation': [{'page': 3,\n",
       "       'matching_text': 'Betriebssysteme Windows, Linux (Ubuntu)'}]}],\n",
       "   'reasoning': 'VERBATIM EXTRACTION, mapped to schema fields. Combined listed Python libraries as frameworks, ML toolkits under frameworks/skills, tools listed as skills, and programming languages as such.'},\n",
       "  'key_accomplishments': {'reasoning': \"Inferred from 'Auszeichnungen' and 'Projekte'. DAAD and Tunisian Government scholarships indicate high academic achievement. Participation as a researcher/developer in AIMS5.0 (with major industry partners) alongside pioneering work in ML and robotics are significant accomplishments.\",\n",
       "   'parsing_confidence': 0.8618428227656375,\n",
       "   'extraction_confidence': 0.32967831834137973,\n",
       "   'confidence': 0.28413089248396317}},\n",
       " 'usage': {'num_pages_extracted': 3,\n",
       "  'num_document_tokens': 1609,\n",
       "  'num_output_tokens': 1788},\n",
       " 'parse_job_id': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_resume.extraction_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df1fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
