{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1f7051",
   "metadata": {},
   "source": [
    "# PostgreSQL Ingestion guard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218cf8e5",
   "metadata": {},
   "source": [
    "A small rag_docs table that stores doc_id + content_hash\n",
    "\n",
    "On startup:\n",
    "1. compute current file hash\n",
    "2. compare to stored hash\n",
    "3. if unchanged skip ingestion\n",
    "4. if changed re-ingest (optionally delete old rows first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf32dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from sqlalchemy import create_engine, text\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def file_hash(path: str) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def ensure_doc_table(engine):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS rag_docs (\n",
    "              doc_id TEXT PRIMARY KEY,\n",
    "              content_hash TEXT NOT NULL,\n",
    "              updated_at TIMESTAMPTZ NOT NULL DEFAULT now()\n",
    "            );\n",
    "        \"\"\"))\n",
    "\n",
    "def get_stored_hash(engine, doc_id: str):\n",
    "    with engine.begin() as conn:\n",
    "        row = conn.execute(\n",
    "            text(\"SELECT content_hash FROM rag_docs WHERE doc_id=:doc_id\"),\n",
    "            {\"doc_id\": doc_id},\n",
    "        ).fetchone()\n",
    "    return row[0] if row else None\n",
    "\n",
    "def upsert_hash(engine, doc_id: str, content_hash: str):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO rag_docs (doc_id, content_hash)\n",
    "            VALUES (:doc_id, :content_hash)\n",
    "            ON CONFLICT (doc_id)\n",
    "            DO UPDATE SET content_hash = EXCLUDED.content_hash, updated_at = now();\n",
    "        \"\"\"), {\"doc_id\": doc_id, \"content_hash\": content_hash})\n",
    "\n",
    "def table_has_rows(engine, table_name: str) -> bool:\n",
    "    with engine.begin() as conn:\n",
    "        # Safe enough if table_name is trusted. If not, validate against a whitelist.\n",
    "        row = conn.execute(text(f\"SELECT EXISTS (SELECT 1 FROM {table_name} LIMIT 1)\")).fetchone()\n",
    "    return bool(row[0])\n",
    "\n",
    "# ---------- your config ----------\n",
    "connection_string = f\"postgresql://postgres:{postgres_pw}@localhost:5432/vector_db\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "TABLE_NAME = \"paul_graham_essay\"\n",
    "DOC_ID = \"paul_graham_essay_source\"  # any stable id you choose\n",
    "SOURCE_PATH = \"/path/to/your/source_file.pdf\"  # or .txt/.md\n",
    "\n",
    "# ---------- vector store ----------\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=\"vector_db\",\n",
    "    host=\"localhost\",\n",
    "    password=postgres_pw,\n",
    "    port=5432,\n",
    "    user=\"postgres\",\n",
    "    table_name=TABLE_NAME,\n",
    "    embed_dim=1536,\n",
    "    hnsw_kwargs={\n",
    "        \"hnsw_m\": 16,\n",
    "        \"hnsw_ef_construction\": 64,\n",
    "        \"hnsw_ef_search\": 40,\n",
    "        \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "    },\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# ---------- ingestion guard ----------\n",
    "ensure_doc_table(engine)\n",
    "\n",
    "current_hash = file_hash(SOURCE_PATH)\n",
    "stored_hash = get_stored_hash(engine, DOC_ID)\n",
    "\n",
    "already_ingested = (stored_hash == current_hash) and table_has_rows(engine, TABLE_NAME)\n",
    "\n",
    "if already_ingested:\n",
    "    # ‚úÖ Fast path: reuse what's already in Postgres (no re-splitting, no re-embedding)\n",
    "    index = VectorStoreIndex.from_vector_store(vector_store=vector_store, storage_context=storage_context)\n",
    "else:\n",
    "    # üîÅ Slow path: ingest only if new/changed or table empty\n",
    "    # Optional but recommended if you want \"replace\" semantics:\n",
    "    # - delete existing rows from TABLE_NAME (and maybe doc metadata)\n",
    "    # - then re-ingest\n",
    "    #\n",
    "    # If you DO want replace semantics, uncomment:\n",
    "    # with engine.begin() as conn:\n",
    "    #     conn.execute(text(f\"TRUNCATE TABLE {TABLE_NAME};\"))\n",
    "\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, storage_context=storage_context, show_progress=True\n",
    "    )\n",
    "    upsert_hash(engine, DOC_ID, current_hash)\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
